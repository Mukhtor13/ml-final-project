{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-02T01:27:08.895079Z","iopub.status.busy":"2024-05-02T01:27:08.894712Z","iopub.status.idle":"2024-05-02T01:27:08.904373Z","shell.execute_reply":"2024-05-02T01:27:08.903494Z","shell.execute_reply.started":"2024-05-02T01:27:08.895047Z"},"trusted":true},"outputs":[],"source":["# Importing necessary libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:27:24.418140Z","iopub.status.busy":"2024-05-02T01:27:24.417151Z","iopub.status.idle":"2024-05-02T01:27:25.416017Z","shell.execute_reply":"2024-05-02T01:27:25.414992Z","shell.execute_reply.started":"2024-05-02T01:27:24.418102Z"},"trusted":true},"outputs":[],"source":["# Reading dataset using pandas\n","train_data = pd.read_csv('/kaggle/input/toxic-dataset/train_data.csv')\n","train_data_external = pd.read_csv('/kaggle/input/toxic-dataset/train_data_external.csv')\n","test_data = pd.read_csv('/kaggle/input/toxic-dataset/test_data.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# Train dataset preparation\n","* Adding new external toxic and non-toxic comments\n","* Balanced dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:27:30.835754Z","iopub.status.busy":"2024-05-02T01:27:30.835026Z","iopub.status.idle":"2024-05-02T01:27:30.850973Z","shell.execute_reply":"2024-05-02T01:27:30.850013Z","shell.execute_reply.started":"2024-05-02T01:27:30.835720Z"},"trusted":true},"outputs":[],"source":["# Renaming dataset columns\n","train_data.rename(columns={'Label': 'label', 'Text': 'comment_text'}, inplace=True)\n","test_data.rename(columns={'ID': 'id', 'Text': 'comment_text'}, inplace=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:27:42.780331Z","iopub.status.busy":"2024-05-02T01:27:42.779503Z","iopub.status.idle":"2024-05-02T01:27:42.805433Z","shell.execute_reply":"2024-05-02T01:27:42.804296Z","shell.execute_reply.started":"2024-05-02T01:27:42.780297Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["label\n","1    6654\n","0     837\n","Name: count, dtype: int64\n"]}],"source":["# Distribution of train data labels\n","distribution = train_data['label'].value_counts()\n","print(distribution)\n","\n","# Dataset has only 837 toxic comments while having 6654 non-toxic comments\n","# Which is a huge data imbalance"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:28:08.076591Z","iopub.status.busy":"2024-05-02T01:28:08.076251Z","iopub.status.idle":"2024-05-02T01:28:08.102633Z","shell.execute_reply":"2024-05-02T01:28:08.101643Z","shell.execute_reply.started":"2024-05-02T01:28:08.076562Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["       label                                       comment_text\n","0          0       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n","1          0  Hey... what is it..\\n@ | talk .\\nWhat is it......\n","2          0  Bye! \\n\\nDon't look, come or think of comming ...\n","3          0  You are gay or antisemmitian? \\n\\nArchangel WH...\n","4          0           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n","...      ...                                                ...\n","15289      0  \"\\n\\n our previous conversation \\n\\nyou fuckin...\n","15290      0                  YOU ARE A MISCHIEVIOUS PUBIC HAIR\n","15291      0  Your absurd edits \\n\\nYour absurd edits on gre...\n","15292      0  \"\\n\\nHey listen don't you ever!!!! Delete my e...\n","15293      0  and i'm going to keep posting the stuff u dele...\n","\n","[15294 rows x 2 columns]\n"]}],"source":["# Get more than 15 000 toxic comments from external dataset\n","toxic_comments = train_data_external[train_data_external['toxic'] == 1]\n","copied_toxic_comments = toxic_comments[['toxic', 'comment_text']].copy()\n","copied_toxic_comments.rename(columns={'toxic': 'label'}, inplace=True)\n","copied_toxic_comments['label'] = copied_toxic_comments['label'].replace({1: 0})\n","copied_toxic_comments.reset_index(drop=True, inplace=True)\n","print(copied_toxic_comments)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:28:23.344442Z","iopub.status.busy":"2024-05-02T01:28:23.344182Z","iopub.status.idle":"2024-05-02T01:28:23.363441Z","shell.execute_reply":"2024-05-02T01:28:23.362565Z","shell.execute_reply.started":"2024-05-02T01:28:23.344419Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["       label                                       comment_text\n","0          1                                              why .\n","1          1              I still love you so much just priva .\n","2          1                         I wish you every success .\n","3          0  She may or may not be a Jew but she 's certain...\n","4          1  I 'm just pointing out our version of mercy an...\n","...      ...                                                ...\n","22780      0  \"\\n\\n our previous conversation \\n\\nyou fuckin...\n","22781      0                  YOU ARE A MISCHIEVIOUS PUBIC HAIR\n","22782      0  Your absurd edits \\n\\nYour absurd edits on gre...\n","22783      0  \"\\n\\nHey listen don't you ever!!!! Delete my e...\n","22784      0  and i'm going to keep posting the stuff u dele...\n","\n","[22785 rows x 2 columns]\n"]}],"source":["# Merging datasets\n","merged_train_data = pd.concat([train_data, copied_toxic_comments], ignore_index=True)\n","print(merged_train_data)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:29:22.147891Z","iopub.status.busy":"2024-05-02T01:29:22.147605Z","iopub.status.idle":"2024-05-02T01:29:22.154250Z","shell.execute_reply":"2024-05-02T01:29:22.153266Z","shell.execute_reply.started":"2024-05-02T01:29:22.147867Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["label\n","0    16131\n","1     6654\n","Name: count, dtype: int64\n"]}],"source":["# Distribution of merged dataset\n","distribution_merged = merged_train_data['label'].value_counts()\n","print(distribution_merged)\n","\n","# Dataset has more than 16 000 toxic comments while having ~6500 non-toxic comments\n","# We can add another 10 000 non-toxic comments to make it balanced"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:29:29.291165Z","iopub.status.busy":"2024-05-02T01:29:29.290838Z","iopub.status.idle":"2024-05-02T01:29:30.706001Z","shell.execute_reply":"2024-05-02T01:29:30.705003Z","shell.execute_reply.started":"2024-05-02T01:29:29.291140Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                      id                                       comment_text  \\\n","0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n","1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n","2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n","3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n","4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n","...                  ...                                                ...   \n","159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n","159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n","159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n","159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n","159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n","\n","        toxic  severe_toxic  obscene  threat  insult  identity_hate  non_toxic  \n","0           0             0        0       0       0              0          1  \n","1           0             0        0       0       0              0          1  \n","2           0             0        0       0       0              0          1  \n","3           0             0        0       0       0              0          1  \n","4           0             0        0       0       0              0          1  \n","...       ...           ...      ...     ...     ...            ...        ...  \n","159566      0             0        0       0       0              0          1  \n","159567      0             0        0       0       0              0          1  \n","159568      0             0        0       0       0              0          1  \n","159569      0             0        0       0       0              0          1  \n","159570      0             0        0       0       0              0          1  \n","\n","[159571 rows x 9 columns]\n"]}],"source":["# Creating new column named as \"non_toxic\" : if comment doesn't belong in any of the class then \"non_toxic\" will be 1 else 0\n","train_data_external['non_toxic'] = train_data_external.iloc[:,2:8].apply(lambda x: 1 if (sum(x)==0) else 0, axis=1)\n","print(train_data_external)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:29:48.897883Z","iopub.status.busy":"2024-05-02T01:29:48.897190Z","iopub.status.idle":"2024-05-02T01:29:48.930950Z","shell.execute_reply":"2024-05-02T01:29:48.930044Z","shell.execute_reply.started":"2024-05-02T01:29:48.897851Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["      label                                       comment_text\n","0         1  \"\\n\\nOh, don't worry about me, Sandstein. I'm ...\n","1         1               Are you trying to dispute that fact?\n","2         1  SWOT analysis \\n\\nThis source – Align Technolo...\n","3         1  cover \\n\\nso, do we want a current or older co...\n","4         1  P.S. It's probably worth setting up a template...\n","...     ...                                                ...\n","9995      1  Because you read it in the Splinter Cell wiki?...\n","9996      1  Do you have a source other than your opinion f...\n","9997      1            REDIRECT Talk:River Rescue (video game)\n","9998      1  I do not blame you. I was basically gang raped...\n","9999      1  \"\\nNancy Pelosi is a high ranking official of ...\n","\n","[10000 rows x 2 columns]\n"]}],"source":["# Get ~10 000 non-toxic comments from external dataset\n","non_toxic_comments = train_data_external[train_data_external['non_toxic'] == 1]\n","copied_non_toxic_comments = non_toxic_comments[['non_toxic', 'comment_text']].copy()\n","copied_non_toxic_comments.rename(columns={'non_toxic': 'label'}, inplace=True)\n","copied_non_toxic_comments = copied_non_toxic_comments.sample(n=10000, random_state=42)\n","copied_non_toxic_comments.reset_index(drop=True, inplace=True)\n","print(copied_non_toxic_comments)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:29:52.056763Z","iopub.status.busy":"2024-05-02T01:29:52.056422Z","iopub.status.idle":"2024-05-02T01:29:52.066030Z","shell.execute_reply":"2024-05-02T01:29:52.065067Z","shell.execute_reply.started":"2024-05-02T01:29:52.056732Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["       label                                       comment_text\n","0          1                                              why .\n","1          1              I still love you so much just priva .\n","2          1                         I wish you every success .\n","3          0  She may or may not be a Jew but she 's certain...\n","4          1  I 'm just pointing out our version of mercy an...\n","...      ...                                                ...\n","32780      1  Because you read it in the Splinter Cell wiki?...\n","32781      1  Do you have a source other than your opinion f...\n","32782      1            REDIRECT Talk:River Rescue (video game)\n","32783      1  I do not blame you. I was basically gang raped...\n","32784      1  \"\\nNancy Pelosi is a high ranking official of ...\n","\n","[32785 rows x 2 columns]\n"]}],"source":["# Merging datasets\n","final_train_data = pd.concat([merged_train_data, copied_non_toxic_comments], ignore_index=True)\n","print(final_train_data)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:29:57.861674Z","iopub.status.busy":"2024-05-02T01:29:57.861306Z","iopub.status.idle":"2024-05-02T01:29:57.869079Z","shell.execute_reply":"2024-05-02T01:29:57.867848Z","shell.execute_reply.started":"2024-05-02T01:29:57.861643Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["label\n","1    16654\n","0    16131\n","Name: count, dtype: int64\n"]}],"source":["# Distribution of final train dataset\n","distribution_final = final_train_data['label'].value_counts()\n","print(distribution_final)\n","\n","# Dataset has balanced toxic and non-toxic comments, shuffled"]},{"cell_type":"markdown","metadata":{},"source":["# Text Cleaning\n","* Lowercase\n","* Expanding contradictions\n","* Removing URLs\n","* Removing non-ASCII characters\n","* Removing special characters (symbols & emojis)\n","* Removing HTML\n","* Removing escape characters\n","* Removing punctuations and spaces which appeared more than once\n","* Removing stop words"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:30:24.758326Z","iopub.status.busy":"2024-05-02T01:30:24.757724Z","iopub.status.idle":"2024-05-02T01:30:24.763585Z","shell.execute_reply":"2024-05-02T01:30:24.762564Z","shell.execute_reply.started":"2024-05-02T01:30:24.758297Z"},"trusted":true},"outputs":[],"source":["# Copied for further text cleaning\n","cleaned_train_data = final_train_data.copy()\n","cleaned_test_data = test_data.copy()"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:30:27.190451Z","iopub.status.busy":"2024-05-02T01:30:27.189623Z","iopub.status.idle":"2024-05-02T01:30:42.407688Z","shell.execute_reply":"2024-05-02T01:30:42.406557Z","shell.execute_reply.started":"2024-05-02T01:30:27.190418Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n","Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n","Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n","\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"]}],"source":["# Intalling the contractions package\n","!pip install contractions"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:33:47.357871Z","iopub.status.busy":"2024-05-02T01:33:47.356904Z","iopub.status.idle":"2024-05-02T01:33:48.603053Z","shell.execute_reply":"2024-05-02T01:33:48.602097Z","shell.execute_reply.started":"2024-05-02T01:33:47.357825Z"},"trusted":true},"outputs":[],"source":["import contractions\n","from nltk.corpus import stopwords\n","\n","stop = set(stopwords.words('english'))\n","\n","# Function which performs text cleaning\n","def clean_text(text):\n","    # Lowercase\n","    text = text.lower()\n","    # Expand contractions\n","    text = contractions.fix(text)\n","    # Remove URLs\n","    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n","    # Remove non-ASCII characters\n","    text = re.sub(r'[^\\x00-\\x7f]', '', text)\n","    # Remove special characters, including symbols, emojis, and other graphic characters\n","    emoji_pattern = re.compile(\n","        '['\n","        u'\\U0001F600-\\U0001F64F'  # emoticons\n","        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n","        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n","        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n","        u'\\U00002702-\\U000027B0'\n","        u'\\U000024C2-\\U0001F251'\n","        ']+',\n","        flags=re.UNICODE)\n","    text = emoji_pattern.sub(r'', text)\n","    # Remove HTML\n","    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n","    text = re.sub(html, \"\", text)\n","    # Remove escape characters\n","    text = re.sub(r'[\\n\\t\\r\\a]', ' ', text)\n","    # Replacing \"\" with \"\n","    text = re.sub(r\"\\\"\\\"\", \"\\\"\", text)\n","    # Removing quotation from start and the end of the string\n","    text = re.sub(r\"^\\\"\", \"\", text)\n","    text = re.sub(r\"\\\"$\", \"\", text)\n","    # Removing Punctuation / Special characters (;:'\".?@!%&*+) which appears more than twice in the text\n","    text = re.sub(r\"[^a-zA-Z0-9\\s][^a-zA-Z0-9\\s]+\", \" \", text)\n","    # Removing Special characters \n","    text = re.sub(r\"[^a-zA-Z0-9\\s\\\"\\',:;?!.()]\", \" \", text)\n","    # Removing extra spaces in text\n","    text = re.sub(r\"\\s\\s+\", \" \", text)\n","    # Remove stop words\n","    text = ' '.join(word for word in text.split() if word not in stop)\n","    return text"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:33:52.816699Z","iopub.status.busy":"2024-05-02T01:33:52.816338Z","iopub.status.idle":"2024-05-02T01:33:57.030890Z","shell.execute_reply":"2024-05-02T01:33:57.030057Z","shell.execute_reply.started":"2024-05-02T01:33:52.816672Z"},"trusted":true},"outputs":[],"source":["# Applying the clean_text function to the 'comment_text' column of the datasets\n","cleaned_train_data['comment_text'] = cleaned_train_data['comment_text'].apply(clean_text)\n","cleaned_test_data['comment_text'] = cleaned_test_data['comment_text'].apply(clean_text)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:34:12.222728Z","iopub.status.busy":"2024-05-02T01:34:12.222032Z","iopub.status.idle":"2024-05-02T01:34:12.519200Z","shell.execute_reply":"2024-05-02T01:34:12.518440Z","shell.execute_reply.started":"2024-05-02T01:34:12.222695Z"},"trusted":true},"outputs":[],"source":["# Save the DataFrame to a CSV file\n","cleaned_train_data.to_csv('cleaned_train_data.csv', index=False)\n","cleaned_test_data.to_csv('cleaned_test_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Training"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:06.402335Z","iopub.status.busy":"2024-05-02T01:40:06.401458Z","iopub.status.idle":"2024-05-02T01:40:06.407008Z","shell.execute_reply":"2024-05-02T01:40:06.406059Z","shell.execute_reply.started":"2024-05-02T01:40:06.402297Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import DistilBertTokenizer, DistilBertModel\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:08.795328Z","iopub.status.busy":"2024-05-02T01:40:08.794427Z","iopub.status.idle":"2024-05-02T01:40:08.799828Z","shell.execute_reply":"2024-05-02T01:40:08.798711Z","shell.execute_reply.started":"2024-05-02T01:40:08.795290Z"},"trusted":true},"outputs":[],"source":["MAX_LEN = 128\n","TRAIN_BATCH_SIZE = 16\n","EPOCHS = 3\n","LEARNING_RATE = 2e-05"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:10.562885Z","iopub.status.busy":"2024-05-02T01:40:10.562127Z","iopub.status.idle":"2024-05-02T01:40:10.574677Z","shell.execute_reply":"2024-05-02T01:40:10.573809Z","shell.execute_reply.started":"2024-05-02T01:40:10.562848Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shape: (27867, 2)\n","Validation data shape: (4918, 2)\n"]}],"source":["# Separating data into training and validation sets\n","train_df, val_df = train_test_split(cleaned_train_data, test_size=0.15, random_state=42)\n","\n","print('Training data shape:', train_df.shape)\n","print('Validation data shape:', val_df.shape)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:12.744354Z","iopub.status.busy":"2024-05-02T01:40:12.743996Z","iopub.status.idle":"2024-05-02T01:40:12.750884Z","shell.execute_reply":"2024-05-02T01:40:12.749898Z","shell.execute_reply.started":"2024-05-02T01:40:12.744327Z"},"trusted":true},"outputs":[],"source":["class DistilBERT_Model(nn.Module):\n","    def __init__(self, num_labels):\n","        super(DistilBERT_Model, self).__init__()\n","        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n","        self.dropout = nn.Dropout(0.1)\n","        self.linear = nn.Linear(self.distilbert.config.hidden_size, num_labels)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.last_hidden_state[:, 0]\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.linear(pooled_output)\n","        return logits"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:14.952740Z","iopub.status.busy":"2024-05-02T01:40:14.952385Z","iopub.status.idle":"2024-05-02T01:40:14.961343Z","shell.execute_reply":"2024-05-02T01:40:14.960297Z","shell.execute_reply.started":"2024-05-02T01:40:14.952709Z"},"trusted":true},"outputs":[],"source":["# Creating Custom Dataset class for Toxic comments and Labels\n","class ToxicDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_length, eval_mode: bool = False):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.eval_mode = eval_mode\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        text = self.data.iloc[idx]['comment_text']        \n","        if not self.eval_mode:\n","            label = self.data.iloc[idx]['label']\n","        else:\n","            label = 0\n","\n","        # Tokenize and encode the text\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        input_ids = encoding['input_ids'].flatten()\n","        attention_mask = encoding['attention_mask'].flatten()\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:17.831691Z","iopub.status.busy":"2024-05-02T01:40:17.830819Z","iopub.status.idle":"2024-05-02T01:40:18.203403Z","shell.execute_reply":"2024-05-02T01:40:18.202582Z","shell.execute_reply.started":"2024-05-02T01:40:17.831654Z"},"trusted":true},"outputs":[],"source":["# Initializing tokenizer and model\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","model = DistilBERT_Model(num_labels=2)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:20.882106Z","iopub.status.busy":"2024-05-02T01:40:20.881298Z","iopub.status.idle":"2024-05-02T01:40:20.890686Z","shell.execute_reply":"2024-05-02T01:40:20.889756Z","shell.execute_reply.started":"2024-05-02T01:40:20.882073Z"},"trusted":true},"outputs":[],"source":["# Defining datasets and data loaders for train, validation, and test\n","train_dataset = ToxicDataset(train_df, tokenizer, MAX_LEN)\n","val_dataset = ToxicDataset(val_df, tokenizer, MAX_LEN)\n","test_output_set = ToxicDataset(cleaned_test_data, tokenizer, MAX_LEN, eval_mode=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False)\n","test_output_loader = DataLoader(test_output_set, batch_size=TRAIN_BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:40:23.809346Z","iopub.status.busy":"2024-05-02T01:40:23.808992Z","iopub.status.idle":"2024-05-02T01:55:54.970425Z","shell.execute_reply":"2024-05-02T01:55:54.969395Z","shell.execute_reply.started":"2024-05-02T01:40:23.809316Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3, Validation Accuracy: 0.9298\n","Epoch 2/3, Validation Accuracy: 0.9215\n","Epoch 3/3, Validation Accuracy: 0.9205\n"]}],"source":["# Define optimizer and loss function\n","optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Training loop\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    for batch in train_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Validation evaluation after each epoch\n","    model.eval()\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            _, predicted = torch.max(outputs, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    val_accuracy = correct_val / total_val\n","    print(f'Epoch {epoch+1}/{EPOCHS}, Validation Accuracy: {val_accuracy:.4f}')"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:56:12.296479Z","iopub.status.busy":"2024-05-02T01:56:12.295828Z","iopub.status.idle":"2024-05-02T01:56:12.663001Z","shell.execute_reply":"2024-05-02T01:56:12.661930Z","shell.execute_reply.started":"2024-05-02T01:56:12.296447Z"},"trusted":true},"outputs":[],"source":["# Saving model\n","torch.save(model,\"dsbert_toxic_balanced.pt\")"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-05-02T01:56:15.381154Z","iopub.status.busy":"2024-05-02T01:56:15.380497Z","iopub.status.idle":"2024-05-02T01:56:27.711298Z","shell.execute_reply":"2024-05-02T01:56:27.710304Z","shell.execute_reply.started":"2024-05-02T01:56:15.381120Z"},"trusted":true},"outputs":[],"source":["# Evaluation on test data\n","model.eval()\n","test_predictions = []\n","\n","with torch.no_grad():\n","    for batch in test_output_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        _, predicted = torch.max(outputs, 1)\n","        test_predictions.extend(predicted.cpu().detach().numpy())\n","\n","# Convert predictions to DataFrame with 'ID' column\n","test_ids = cleaned_test_data['id']\n","predictions_df = pd.DataFrame({'ID': test_ids, 'Label': test_predictions})\n","\n","# Save predictions to CSV\n","predictions_df.to_csv('distilbert_nn2.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4871382,"sourceId":8218148,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
